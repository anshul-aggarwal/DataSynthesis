\documentclass[]{article}

%opening
\title{Differentially Private Data Synthesis}
\author{Anshul Aggarwal\\A0191501R}

\date{CS4257}

\begin{document}

\maketitle

\section{Introduction}

In this project, the objective is to construct a privacy-preserving synthetic dataset from a given sensitive dataset. The synthesized dataset must be generated in a differentially private manner, and must satisfy two conditions to preserve utility:

\begin{itemize}
    \item The summary statistics (marginal distribution over each attribute) of the synthesized data must be close to the summary statistics of the actual data.
    \item The cluster centres of the synthesized data must be close to the cluster centres of the given dataset.
\end{itemize}

\section{Dataset}

\begin{itemize}
    \item 197,324 data records
    \item 600 binary attributes
    \item Unclassified data, but it is known that the data can be divided into 100 categories.
\end{itemize}

\section{Methodology}

First, k-means is run on the actual data set, using k = 100 as a parameter (the number of clusters). The distance is simply defined as the POPCOUNT of the XOR of two binary sequences representing two data records.

This generates the following results.

\begin{itemize}
    \item 100 cluster centres, $c_i, i = 1, \dots, 100$
    \item 100 sets of data records $C_1, \dots, C_{100}$, each corresponding to a cluster $i = 1, \dots, 100$.
    \item Normalized sizes of each cluster $i$, given by $\frac{|C_i|}{\sum_{j=1}^{100} |C_j|}$.
    \item The mean, $\mu_i, i = 1, \dots, 100$ and standard deviation, $\sigma_i, i = 1, \dots, 100$ of distances of points (in set $C_i$) belonging to each cluster $i$ from the cluster centre $c_i$.
\end{itemize} 

There are two instances where noise is added. The first is to the cluster centres. Noise is added over the cluster centres by randomly flipping some bits, with the number of bits to be flipped decided by a random number from a normal distribution.

The second instance is adding noise to the normalized size of each cluster, again using a normal distribution.

There is no need to add noise to the mean and standard deviation values of the distances of cluster data records from respective cluster centres, which signify the distribution of the points around the cluster centre. This is because a common distribution --- which is the averages over all clusters for the above two values, is used as a common distribution around the cluster centres, for synthesizing data. This was possible because it was observed empirically that the mean and standard deviation of distances of cluster records from corresponding cluster centres are similar.  

Further, armed with the information obtained above, synthetic data was generated. Proportional to the noisy relative cluster size, records were generated by flipping random bits in the corresponding noisy cluster centre, with the number of bits flipped dependent on the common distribution obtained above. This preserves the clusters, as the records are generated around the noisy cluster centre. The only challenge remaining is ensuring the summary statistics are similar to that of the original dataset.

\section{Observations}

Some experiments were performed over the synthetic data and the actual data, and the following observations were made.

\begin{itemize}
    \item The difference between the summary statistics of the actual data with the synthetic data, is similar to the difference between the summary statistics of a randomly sampled set of 10,000 records from the actual data with the synthetic data.
    \item The distribution patterns are embedded in the cluster centres generated. Flipping a few random bits in the cluster centre will not only provide synthesized data records, but will also destroy some (but not all) correlations and cluster centre features, which is a cost of making the data private.
    
\end{itemize}

\section{Differentially private k-means}

There are two approaches to ensure differentially private k-means \cite{smoothsenst}. The first is to add noise to the final cluster centres obtained after running standard k-means. This ensures convergence, and we get a fixed bound of error in the cluster centres. 

The alternative is to add some small noise at the end of every epoch in the cluster centres. This enforces stronger privacy guarantees, but there are two flaws --- the algorithm is then not guaranteed to converge, and if the number of epochs it runs for is large, the noise added will be too much, making the result practically useless. Therefore the first method was preferred.


\section{Privacy mechanism}
The two stages of adding noise --- adding noise to cluster centres, and adding noise to the relative cluster sizes, are working on different attributes of the same dataset. So these two mechanisms effectively compose. The privacy guarantees of the mechanisms is discussed below.

\subsection{Adding noise to cluster centres}
Sensitivity is the max distance of a point in the cluster from the cluster centre, divided by the number of points in the cluster.

Empirically, the maximum value for sensitivity for the dataset as clustered was observed to be 
\[\Delta f \approx 0.018\]

Let $\delta_1 = 1$, and $\varepsilon_1$ be the differential privacy metrics for this mechanism. Then using the Gaussian mechanism definition (\cite{diffp} -- Theorem A.1), we get

\[c^2 > 2\ln(1.25/1)\]
or \[c > 0.668\]
So, \[\sigma \geq 0.668\times 0.018/\varepsilon_1\]
or \[\sigma \geq 0.012/\varepsilon_{1}\]

Setting $\varepsilon_1 = 2$, we get $\sigma \geq 3.6$, considering 600 different attributes.

\subsection{Adding noise to relative cluster sizes}
Sensitivity is the maximum xhange in relative cluster size on adding or removing one record.

Empirically, the maximum value for sensitivity for the dataset as clustered was observed to be 
\[\Delta f \approx 0.001\]

Let $\delta_2 = 1$, and $\varepsilon_2$ be the differential privacy metrics for this mechanism. Then using the Gaussian mechanism definition (\cite{diffp} -- Appendix A Theorem A.1), we get, similar to the previous case,

\[\sigma \geq 0.668\times 0.001/\varepsilon_1\]
or \[\sigma \geq 0.0007/\varepsilon_{2}\]

Setting $\varepsilon_2 = 1$, we get $\sigma \geq 0.0007$.

\subsection{Composing the two mechanisms}

The two mechanisms can simply be composed (\cite{diffp} -- Section 3.5). We get

\[\varepsilon = \varepsilon_1 + \varepsilon_2\]
or \[\varepsilon = 3\]

For other values of $\varepsilon$, we can alter the corresponding values of $\sigma$ for the Gaussian mechanisms.

\begin{thebibliography}{1}
    \bibitem{smoothsenst} K. Nissim, S. Raskhodnikova and A. Smith. Smooth Sensitivity and Sampling in Private Data Analysis, In proceedings of STOC'07, June 2007.
    \bibitem{diffp} C. Dwork, A. Roth. The Algorithmic Foundations of Differential Privacy, 2014.
\end{thebibliography}

\end{document}
